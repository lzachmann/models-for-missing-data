[{"id":0,"href":"/models-for-missing-data/docs/1-guide/c-outputs/output-dir/00-input/","title":"00-input","section":"The output directory","content":"00-input | model inputs #  R objects required to recreate analyses (JAGS inputs) and lookup tables.\n   File Description     calendar-and-relative-years.csv A lookup table showing how calendar years are encoded as (zero-indexed) relative years. The first year of the study is always year 0.   coda-vars.rds A list of the variables for which coda samples are drawn   complete-covariates-data.csv The covariate information used by this model   covariate-moments.rds Mean and standard deviation used to scale each of the covariates, used to back out of scaled version   eval-mean-for-tv-covariates.rds What is this file?   jags-data.rds A list containing the data   jags-info.rds Data frame containing the JAGS and CODA variables to be monitored, in addition to several other \u0026rsquo;environment\u0026rsquo; settings/variables used during the original pass through the analysis pipeline   jags-inits.rds A list containing initial values   jags-n-iters.rds The number of iterations used for adaptation, burn-in, and subsequent sampling   jags-vars.rds What is this file?   site-ids-and-indices.csv Mappings of site IDs (typically character or non-sequential numeric IDs) to sequential indices   site-in-stratum-info.csv Complete mappings of site IDs to indices, stratum IDs to stratum indices, and (most importantly, for our purposes) indices for sites within each stratum   state-variable-data-summary.txt Used as a straight-face test for number of records, data types, etc.   state-variable-data.csv The complete, pre-processed dataset used to construct many of the objects described above   stratum-ids-and-indices.csv Mappings of stratum IDs (stratum names) to their corresponding sequential indices   vars-to-watch.txt The names of variables to be monitored (and saved) by JAGS    "},{"id":1,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iv-analysis-extras/conditions/","title":"Conditions","section":"Analysis / extras","content":"Conditions #  Modify the default behavior of pred-type means.\nSyntax #  trend conditions:  Botanist: JA Usage #  See the object types entry for a more thorough introduction to this topic.\n"},{"id":2,"href":"/models-for-missing-data/docs/1-guide/b-config-files/i-design-metadata/","title":"Design metadata","section":"Config files","content":"Design metadata #  Two high-level \u0026ldquo;attributes\u0026rdquo; files are required for all analyses. So long as the basic details of the sampling design they describe do not vary for different measures within a park, or different park units within a network, they only need to be specified once.\nThe config file tree #  The file tree structure needed to configure analysis of data from a given park unit (\u0026lt;unit code\u0026gt;) in a given network (\u0026lt;network code\u0026gt;) must look like the following\n. # project root └── assets └── \u0026lt;config dir\u0026gt;/ └── \u0026lt;network code\u0026gt;/ ├── \u0026lt;unit code\u0026gt;/ │ ├── _park-level-attributes.yml │ └── \u0026lt;analysis file\u0026gt;.yml └── _network-level-attributes.yml  The name of \u0026lt;config dir\u0026gt; is arbitrary. For the demo analyses it\u0026rsquo;s _config, while for the \u0026ldquo;uplands\u0026rdquo; status and trends work we\u0026rsquo;ve used uplands-config.\nThe directory structure, as shown, is relative to the root of the project on your file system. The contents of \u0026lt;analysis file\u0026gt;.yml are described in the ensuing sections of the guide. To take a real-world example from an analysis of species richness data at Little Bighorn Battlefield National Monument (LIBI), in Montana \u0026ndash; a park within Rocky Mountain Network (ROMN) \u0026ndash; the complete file tree might look like the following:\n. └── assets └── uplands-config/ └── ROMN/ ├── LIBI/ │ ├── _park-level-attributes.yml │ └── richness.yml └── _network-level-attributes.yml  Network-level attributes #  These attributes, which appear in the file _network-level-attributes.yml, consist of several key-value pairs used to define the park unit code (unit code column) by whatever name it goes by in the raw data, the name of the column containing the site ID (site id column), and a nested set of key-value pairs used to describe the date associated with each observation.\nunit code column: Park site id column: SiteName event date info:  date-time column: Year  date-time format: Y! # see lubridate::parse_date_time() for details You can also specify multiple date-time formatting options if individual data files for a network use different datetime standards. Here\u0026rsquo;s another example of a _network-level-attributes.yml file for analyses from Northern Colorado Plateau Network:\nunit code column: Unit_Code site id column: Plot_ID event date info:  date-time column: Start_Date  date-time format:  - Y!-m!*-d! I!:M!:S!  # see lubridate::parse_date_time() for details  - Y!-m!*-d! Park-level attributes #  Park-level metadata, stored in _park-level-attributes.yml, cannot be defined at a higher level because most, if not all, of this information applies only to an individual park, and not to other park units in the network. Specifically, we use this file to describe the name of the column in the raw data that defines the strata (stratum id column) and the associated stratum areas (stratum area info).\nThese areas, in turn, are used internally to compute a weighted mean at the park scale. Each entry beneath stratum area info must correspond to the actual stratum IDs in the column indicated by stratum id column. If there are no strata, then you can supply the same column used by _network-level-attributes.yml to indicate the unit code, and supply a single stratum area for the park.\nstratum id column: MDCATY stratum area info:  Gulley1: 684731  Gulley2: 138247  Upland: 1063552 .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#444;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative} Note\nOnly the stratum id\u0026rsquo;s appearing beneath stratum area info are included in analysis. If your original response data contain strata A, B, and C, but _park-level-attributes.yml includes just A and C, then records associated with stratum B are automatically removed prior to analysis.\n The number assigned to each stratum under stratum area info corresponds to the total number of sites \u0026ndash; regardless of the actual units \u0026ndash; that could have been sampled in that stratum. In this example there were 684731 potentially sampleable sites in Gulley1. The proportion of the park represented by Gulley1 is 684731 / (684731 + 138247 + 1063552) = 0.3629579.1\nIn most cases, the sites actually sampled in any given stratum represents a tiny fraction of that stratum\u0026rsquo;s area (e.g., \u0026lt;1%). In cases where sampled sites represent a larger proportion of the total stratum area, we may need to apply finite population correction, which we\u0026rsquo;ll describe in another section of this guide.\n  Does the unit of the stratum areas matter so long as they are in the same unit? No, not yet, because these are only used to create the (normalized) stratum weights.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":3,"href":"/models-for-missing-data/docs/0-getting-started/installation/","title":"Installation","section":"Getting started","content":"Installation #  Obtaining a copy of the repository #  New here? #  To clone the repository, open a terminal1 and run the following command from the directory into which you\u0026rsquo;d like to place the project (e.g., from ~/repos).\ngit clone https://github.com/lzachmann/models-for-missing-data.git [DIRNAME] DIRNAME is optional, and specifies the name of the directory into which the project will be cloned on your local machine. You could call it \u0026ldquo;m4md\u0026rdquo; for instance, if you wanted something a bit shorter than the default \u0026ldquo;models-for-missing-data.\u0026rdquo;\nExisting I\u0026amp;M uplands member? #  If you\u0026rsquo;re a member of the team that helped to create this tool, you may want to fetch the uplands data and analysis config files we\u0026rsquo;ve been using, which are kept as private submodules on GitLab.2\ngit clone --recurse-submodules --remote-submodules \\  https://github.com/lzachmann/models-for-missing-data.git [DIRNAME] The git clone command above will recurse through all of the project submodules and ask you to authenticate with GitLab as necessary.\n  Windows users will need to use Git Bash to do this, which comes with your installation of Git for Windows.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n If this command doesn\u0026rsquo;t work, try updating Git (--remote-submodules is only available in newer versions of Git). Alternatively, try removing --remote-submodules from the git clone command.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":4,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iii-analysis-model/likelihood-function/","title":"Likelihood function","section":"Analysis / the model","content":"Likelihood function #  The likelihood statement specifies the probability distribution that will be used to describe the response variable. The available options depend on your data, so knowing what type of variable you\u0026rsquo;re working with is essential.\nSyntax #  # Likelihood. For counts, one or both of: poisson, negative-binomial. likelihood:  - poisson  - negative-binomial Usage #  In some cases \u0026ndash; a model for soil stability observations \u0026ndash; there is only one plausible, implemented likelihood function (ordinal-latent-normal). In other cases \u0026ndash; species richness \u0026ndash; there might be several available options (poisson, negative-binomial, and their zero-inflated counterparts). In cases where you specify multiple likelihoods, the model API will create a separate analysis for each, and the relative performance of each can be evaluated using model diagnostics, posterior predictive checks, and information criteria.\nOptions #     Option Description Example     beta Continuous variables with values between 0 and 1 Ocular cover   beta-binomial1 Overdispersed binomial data    binomial \u0026ldquo;Successes\u0026rdquo; in a given number of trails The number of \u0026ldquo;hits\u0026rdquo; of invasive species in   \\(n\\)  point intercepts along a transect   gamma2 Continuous, non-negative quantities    gen-pois Underdispersed count data    hurdle-ordinal-latent-beta Ordinal data arising from a beta distributed latent variable Plant cover measured using Daubenmire cover classes   lognormal3 Continuous, non-negative quantities    negative-binomial Overdispersed counts (with support for either fixed stratum-level or hierarchical site-level variances modeled using a moment match for  \\(\\kappa\\)  )    negative-binomial-simple Overdispersed counts (with fixed stratum-level dispersion modeled directly using  \\(\\kappa\\)  )    ordinal-latent-normal Ordinal data arising from a normally distributed latent variable Soil stability   poisson Counts Richness or shrub density   zero-inflated-beta-binomial Binomial data that exhibit overdispersion and excess zeros    zero-inflated-binomial Binomial data with an excess of zero counts    zero-inflated-negative-binomial Count data that exhibit overdispersion and excess zeros    zero-inflated-poisson Count data with an excess of zero counts       A misnomer. We don\u0026rsquo;t use the canonical beta-binomial parameterization. It was too slow / unwieldy. Instead, we use a binomial model with an extra epsilon term in the model for the mean.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n \u0026ldquo;The log of a lognormal random variable is\u0026hellip; normal. It\u0026rsquo;s symmetric.\u0026rdquo; See Glen_b\u0026rsquo;s answer here.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n \u0026ldquo;The log of a gamma distributed random variable is left-skew. Depending on the value of the shape parameter, it may be quite skew or nearly symmetric.\u0026rdquo; See again Glen_b\u0026rsquo;s answer here.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":5,"href":"/models-for-missing-data/docs/4-internals/model-builder/","title":"Model builder","section":"Internals","content":"Model builder #  The shell script compile-jags-file.sh builds JAGS model files using several arguments. The arguments \u0026ndash; which correspond to the likelihood, the deterministic function, group-level effects parameterization (random intercepts and slopes vs. random intercepts only), the presence or absence of additional covariates and, finally, the path to write to \u0026ndash; are supplied via the \u0026lsquo;MODEL\u0026rsquo; block in the YAML file for an analysis. For purposes of development or debugging, compile-jags-file.sh can be sourced from the command line with an optional output directory as such:\n./src/model-builder/compile-jags-file.sh \\ \u0026lt;likelihood\u0026gt; \u0026lt;deterministic-function\u0026gt; \u0026lt;group-level-effects\u0026gt; \u0026lt;covariates\u0026gt; \\ \u0026lt;write-path\u0026gt; For example:\n./src/model-builder/compile-jags-file.sh \\ poisson exponential b0-b1 w1 \\ assets The model compiler supports both random intercepts (b0) or random intercepts / random slopes (b0-b1) models with and without covariates.\n"},{"id":6,"href":"/models-for-missing-data/posts/non-ignorable-missingness/","title":"Non-ignorable missingness","section":"Posts","content":" Statistics is basically a missing data problem!\n \u0026ndash; Little 2013\nNearly all samples \u0026ndash; whether by design or by accident \u0026ndash; are incomplete. We very rarely make a complete census of all individuals in a population or all sites on a landscape. Sometimes we don\u0026rsquo;t collect, or can\u0026rsquo;t collect, complete information for individual samples or measures. For instance, we might know an animal was alive when it was last seen, so we know it survived at least that long, but know nothing about its current status. Or we might have information on the coverage of an invasive species down to a certain patch size, beyond which patches are too small or numerous to survey.\nAll of these examples involve missing data. It probably goes without saying that estimating population level parameters in light of such \u0026ldquo;missingness\u0026rdquo; is a challenge. We cannot compute a population mean if one or more values are missing.\n 6 NA 9 NA 9 NA 5 6 9 7 2  The mean for such a string of numbers is undefined.1 In some settings these missing data can be safely ignored, but these circumstances are rarely met in ecological studies. One helpful \u0026ldquo;trick\u0026rdquo; is to consider how the problem would be solved had the data been complete, and to consider what we might do to arrive at complete data. An incomplete data perspective provides a general framework for resolving this sampling problem and making inference.\n  If you\u0026rsquo;re an R person and you thought, \u0026ldquo;why not just include an na.rm = TRUE in the call to mean()\u0026rdquo;, kudos! You would indeed obtain a real number, but we don\u0026rsquo;t yet whether we can safely ignore these NA values.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":7,"href":"/models-for-missing-data/docs/1-guide/c-outputs/object-types/","title":"Object types","section":"Outputs","content":"Object types #  There are two fundamental types of objects created by the model API. The objects are distinguished by their prefix \u0026ndash; either hat or pred. hat-type objects involve an evaluation of the mean over time, but holding any other covariates at their mean (or at zero, in the case of indicators / dummy variables). pred-type objects use the known values of each covariate, at each site and timestep, while evaluating the mean. This critical difference between object types produces outputs that we have colloquially referred to as \u0026ldquo;smooth\u0026rdquo; (hat) vs. \u0026ldquo;bumpy\u0026rdquo; (pred) results. The hat results are smooth because the only terms in play are the intercept and time slope. The pred results can be bumpy if: 1) the covariates included are influential, and 2) they vary from year-to-year.\nSite, stratum, and park level inference #  At the site-scale, we make predictions \u0026ndash; whether hat or pred \u0026ndash; only to sites that were sampled. At a stratum scale, things work a bit differently.\nModifying the default behavior of pred-type means #  Recall that pred-type means include all of the covariates used in a model. There are times when some of our covariates might produce results that are less-than-interesting from an ecological perspective. This is often the case for a nuisance variable. Let\u0026rsquo;s say we have two botanists, one of which was less experienced than the other, and tended to identify fewer species on average than the more experienced botanist. In a model of species richness, the default behavior of pred-type objects would produce means that \u0026ldquo;jump\u0026rdquo; up at sites / times in which the more experienced botanist was making observations, and down otherwise. These changes in the mean aren\u0026rsquo;t being caused by ecological factors, they\u0026rsquo;re entirely a result of the observer. We can change the way pred-type means are evaluated using the trend conditions block, described here. This block of the analysis config file can also be used to \u0026ldquo;fix\u0026rdquo; continuous variables at a specific value.\n"},{"id":8,"href":"/models-for-missing-data/docs/1-guide/a-data/i-y-info/","title":"Response data","section":"Data","content":"Response data #  The response data include the observations we are trying to model, as well as columns with identifiers (indices, IDs, datetime strings) for all relevant sampling design information. Elements of the sampling design often seen in long-term monitoring data include the following:\n   Design element Examples     observational units transect, quadrat, plot   sampling units plot, site   stratification stratum   date / event times MM/DD/YYYY, YYYY    Format #  The response data are stored as flat files. The key characteristic of a flat file is that each row represents a single observation, while the columns describe values associated with the observation and the design features described above. These files are typically text files with no special word processing or markup. The file can be CSV, XLS, XLSX, GZ, or RDS. For ease of use, readability, and other reasons, we generally recommend CSV.\nExample #  The response data below contain species richness observations for forb (native.forb.rich) and grass-like (native.gram.rich) species from Little Bighorn Battlefield National Monument (LIBI), in Montana. Here, we see the first and last six rows of the data.\n   Row Park MDCATY SiteName Year Transect Plot native.forb.rich native.gram.rich     1 LIBI Gulley1 LIBI_001 2011 1 A 6 5   2 LIBI Gulley1 LIBI_001 2011 1 B 5 5   3 LIBI Gulley1 LIBI_001 2011 1 C 4 2   4 LIBI Gulley1 LIBI_001 2011 1 D 6 8   5 LIBI Gulley1 LIBI_001 2011 2 A 6 7   6 LIBI Gulley1 LIBI_001 2011 2 B 4 6   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;   1105 LIBI Upland LIBI_050 2019 2 A 5 2   1106 LIBI Upland LIBI_050 2019 2 B 4 6   1107 LIBI Upland LIBI_050 2019 2 C 3 3   1108 LIBI Upland LIBI_050 2019 3 A 2 1   1109 LIBI Upland LIBI_050 2019 3 B 2 1   1110 LIBI Upland LIBI_050 2019 3 C 3 2    Although they may go by different names, we see many of the design elements appearing in columns. Our sampling units are sites (SiteName) within strata (MDCATY). Individual observations are indexed by the unique combinations of Transect and Plot within each site. All of the sites in this dataset come from a single park unit (LIBI). The calendar year in which the observations were made is given in the column Year.\n% select(-EventName, -OneEventPerYear, -native.rich) %% arrange(SiteName, Year) %% mutate(Row = row_number()) %% relocate(Row, Park) write_csv(bind_rows(head(d), tail(d)), 'docs/website/content/docs/guide/data/richness.csv') -- From data to model #  We\u0026rsquo;ll see how to declare various aspects of the response information in the data block of the analysis config files in another section of this guide. For now, we will leave things as they stand, with two quick notes / caveats:\n Unlike many design based approaches, which aggregate observations within or across sampling units (using a mean, for instance), we work with the raw observations themselves. As we begin to develop models for the data, it will be important to know what type of data your observations represent. If you are expecting to use covariates in your model, the names of each design element must be consistent across response and covariate data files. The reason for this requirement is that the analysis pipeline performs auto joins. If the column containing site information in the response data is called SiteName, but Site in the covariate data, the program won\u0026rsquo;t know they\u0026rsquo;re intended to be the same. Additionally, even the entries within a column must be the same. Thus, if a site is called LIBI_001 in the response info it must be given the same name in the covariate info. If, in the covariate info, the sites appear without the prefix for unit code (e.g., 001), the join will fail.  "},{"id":9,"href":"/models-for-missing-data/docs/1-guide/b-config-files/ii-analysis-data/response-info/","title":"Response info","section":"Analysis / the data","content":"Response information #  The usual case #  In the usual case, we are working with a single vector of observations (a single column of data in a flat file). Below, we see the first few lines of the data block for an analysis of count-type data from Little Bighorn Battlefield National Monument (LIBI), in Montana (a park within the Rocky Mountain Network). The file, rich.yml, lives in the directory assets/uplands-config/ROMN/LIBI.\n# ==== DATA ===================================================================  response info:  file: data/ROMN/LIBI_richness_20171208_r.csv  state variable:  response column:  - native.rich  - native.forb.rich  description:  - Native species richness  - Native forb species richness  sampling method: plot  sample id column(s):  - Transect  - Plot The response info section of the data block specifies the file (see the response data) for more detail on the contents of this file), the name of the column containing the response variable of interest (response column), a corresponding human-readable description for each response variable (description), and the names of the columns required to identify individual observations (sample id column(s)). In some cases, sample id column(s) is a single column, while in others it\u0026rsquo;s multiple.\n.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#444;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative} Note\nThere is one additional option for count models requiring offsets.\nresponse info:  file: assets/uplands-data/CASP/modified/spp_comp_0to25.csv  state variable:  response column:  - n_spp  description:  - Richness per acre  offset column: n_acres_per_belt # plot_size/4046.86, e.g., (20*50)/4046.86  sampling method: plot  sample id column(s):  - plot_name  "},{"id":10,"href":"/models-for-missing-data/docs/1-guide/c-outputs/output-dir/01-diagnostics/","title":"01-diagnostics","section":"The output directory","content":"01-diagnostics | model diagnostics #  Overview #  Diagnostics are applied to monitor whether the Markov chains have converged.\n   File Description     funnel/ Full plots   trace/ Traceplots   convergence-diagnostics.txt The Gelman and Rubin (Citation: 1992Gelman,\u0026#32; A.\u0026#32;\u0026amp;\u0026#32;Rubin,\u0026#32; D. \u0026#32; (1992). \u0026#32;Inference from iterative simulation using multiple sequences. Statistical science,\u0026#32;7(4).\u0026#32;457–472. ) potential scale reduction statistic,   \\(\\hat{R}\\)  , for selected parameters.  \\(\\hat{R}\\)  measures the ratio of the average variance of samples within each chain to the variance of samples pooled across all chains. If the chains have converged to a common distribution,  \\(\\hat{R} \\simeq 1\\)  , otherwise  \\(\\hat{R} \u0026gt; 1\\)  . We hope to see  \\(\\hat{R} \u0026lt; 1.1\\)  .    Subdirectories #  funnel/ | funnel plots #  Bivariate scatter plots created by plotting the posterior values of \u0026ldquo;local\u0026rdquo; parameters (a group-level effect for site  \\(j\\)  ) against a \u0026ldquo;global\u0026rdquo; scale parameter on which it depends ( \\(\\sigma_{\\beta_0}\\)  ). The problem that these plots are designed to detect is discussed here. The issues presented by strong funnel-like shapes in these scatterplots can be resolved with the non-centered parameterization.\ntrace/ | traceplots #  The traceplot is essentially a time series plot of the Markov chains. It shows the evolution of a parameter vector over the MCMC iterations of each Markov chain. We\u0026rsquo;re hoping to see the chain exploring the same region of parameter values, with good mixing.\nReferences #    Gelman\u0026#32;\u0026amp;\u0026#32;Rubin (1992)  Gelman,\u0026#32; A.\u0026#32;\u0026amp;\u0026#32;Rubin,\u0026#32; D. \u0026#32; (1992). \u0026#32;Inference from iterative simulation using multiple sequences. Statistical science,\u0026#32;7(4).\u0026#32;457–472.     "},{"id":11,"href":"/models-for-missing-data/docs/1-guide/b-config-files/","title":"Config files","section":"Guide","content":"Config files #  We use YAML to create analysis configuration files. These files are intended to be human-readable, and they describe how a model relates to the data, including nonignorable aspects of the sampling design. We organize information about the sampling design, the data, and the model in this way:\n Design metadata The analysis config file, which in turn consists of:  The data (response, site location, and covariate information) The model (likelihood, link function(s), group-level effects, predictor variables, etc.) Other conditions or quantities (posterior predictive checks, etc.)    We call these subcomponents of the analysis config file \u0026ldquo;blocks\u0026rdquo;. The blocks provide sensible organization to the specifications of an analysis.\nFor more background on YAML files, see this helpful tutorial.\n"},{"id":12,"href":"/models-for-missing-data/docs/1-guide/a-data/ii-x-info/","title":"Covariate data","section":"Data","content":"Covariate data #  Covariates are variables that are expected to change with the response variable \u0026ndash; they covary in some way with the observations we seek to model. The definition of covariates varies widely online and in the literature. For our purposes, we use the term covariate to describe any variable (whether continuous or discrete) that might influence the mean of the response variable we are interested in. In many cases their effects are of direct interest in the analysis (weather or terrain, for instance). In other cases, a covariate might be \u0026ldquo;nuisance variable\u0026rdquo; \u0026ndash; a fact or feature that is of no particular interest in itself, but nonetheless might be necessary to build a proper model and develop robust inference. Examples of nuisances include sudden changes in protocol or observers.\nCovariates can be static or dynamic. A variable like the elevation of site varies from site to site, but not in time (at least on the time scales we are interested in). Variables involving weather, such as precipitation, are more interesting. A long-run summary (e.g., 30-year average rainfall), like our static terrain variable, might only vary in space. However, an annualized metric will vary in time and space.\nThe granularity of information can also vary. Sometimes the information we have is rather coarse, so many sites have the same value. Gridded climate data are an excellent example of relatively coarse (e.g., 1km gridcell) data. Adjacent sites falling into the same gridcell will have the same value.\nFormat #  As with the response data, covariates are typically stored as flat files.\nExample #  % select(MDCATY, SiteName, Year, Botanist, deficit.pregr) %% arrange(SiteName, Year) %% mutate(Row = row_number()) %% relocate(Row) write_csv(bind_rows(head(d), tail(d)), 'docs/website/content/docs/guide/data/richness-covariates.csv') -- The data below contain site (SiteName), stratum (MDCATY), time (Year), and covariate information (Botanist and deficit.pregr) for sites from Little Bighorn Battlefield National Monument (LIBI), in Montana. Here, we see the first and last six rows of the data.\n   Row MDCATY SiteName Year Botanist deficit.pregr     1 Gulley1 Grid_100 2009 DS 418.7766661   2 Gulley1 Grid_100 2010 DS 434.9612421   3 Gulley1 Grid_100 2011 JA 408.9919742   4 Gulley1 Grid_100 2012 JA 450.2639661   5 Gulley1 Grid_100 2013 JA 532.0683071   6 Gulley1 Grid_100 2014 JA 437.0008004   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;   3240 Upland LIBI_050 2014 JA 381.9736062   3241 Upland LIBI_050 2015 JA 328.6534898   3242 Upland LIBI_050 2016 JA 431.6948948   3243 Upland LIBI_050 2017 JA 402.8102409   3244 Upland LIBI_050 2018 JA 393.2275301   3245 Upland LIBI_050 2019 JA 247.7891026    It\u0026rsquo;s worth pointing out a few things. First, we see two different types of variables \u0026mdash; a categorical variable containing the initials of the observing botanist (Botanist), and a continuous variable for pre growing season water deficit (deficit.pregr). Second, the spatial granularity of the covariates is limited to the site, but both variables appear to vary in time. Finally, we see more rows than we might expect based on the example data seen in the response data section. The reason for this is two-fold:\n The covariate data at a site include values for all years over the duration of the study, whether that site was sampled or not. In general, sites are visited on a rotating basis, meaning they\u0026rsquo;re not sampled every year. There are sites (e.g., Grid_100) that were never sampled. We include this information because it\u0026rsquo;s needed to make inference at the park scale, and because we\u0026rsquo;re interested in making predictions of our focal response variables at every site on the landscape, whether it was visited by field crews or not.  From data to model #  We\u0026rsquo;ll see how to include covariates in models using the XX and YY blocks of the analysis config files in other sections of this guide.\n"},{"id":13,"href":"/models-for-missing-data/posts/trend-vs-trajectory/","title":"Disentangling concepts of status, trend, and trajectory","section":"Posts","content":"The terms status and trend are ubiquitous in resource monitoring and management settings. To be useful and robust, however, they require precise (mathematical) definitions. It has been my experience that misunderstanding these terms can lead to misapplication of model predictions and to researchers and managers drawing the wrong conclusions from the data. In this post we show how relatively simple, even intuitive, definitions for each of these terms clarifies their intent, and improves the insights provided by models of monitoring data.\nFor context, it is helpful to see how these terms have been used previously in the literature\n The ‘term “trend” [is] a description of an overall tendency, without regard to fluctuations in the trajectory. The distinction between the terms has important consequences for analysis and interpretation of survey data. Trend describes the change in a population over a specific interval; trajectory describes the manner in which the change occurred.\n \u0026ndash; Link and Sauer 1998\nTrend vs. trajectory (Citation: Link\u0026#32;\u0026amp;\u0026#32;Sauer,\u0026#32;1998Link,\u0026#32; W.\u0026#32;\u0026amp;\u0026#32;Sauer,\u0026#32; J. \u0026#32; (1998). \u0026#32;Estimating population change from count data: Application to the north american breeding bird survey. Ecological applications,\u0026#32;8(2).\u0026#32;258–268. ) .\n References #    Link\u0026#32;\u0026amp;\u0026#32;Sauer (1998)  Link,\u0026#32; W.\u0026#32;\u0026amp;\u0026#32;Sauer,\u0026#32; J. \u0026#32; (1998). \u0026#32;Estimating population change from count data: Application to the north american breeding bird survey. Ecological applications,\u0026#32;8(2).\u0026#32;258–268.     "},{"id":14,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iv-analysis-extras/finite-pop/","title":"Finite population correction","section":"Analysis / extras","content":"Finite population correction #  When the size of the sample collected is a significant proportion of the overall population, then we must use a finite population correction, a topic we introduce briefly in another post.\nSyntax #  finite population correction: true finite population info:  file: assets/uplands-data/ROMN/LIBI_SampledUnsampled_Ratio.csv  columns with the number of sampled and unsampled sites:  - \u0026#39;# sampled sites\u0026#39;  - \u0026#39;# unsampled sites\u0026#39;  covariate info includes unsampled sites: true Usage #  "},{"id":15,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iii-analysis-model/link-function/","title":"Link function","section":"Analysis / the model","content":"Link function #  The deterministic link function for the regression on the mean ensures that the mean we are trying to model has the appropriate support for the probability distribution from which our observations arise.\ndeterministic model:  - linear  - exponential "},{"id":16,"href":"/models-for-missing-data/docs/1-guide/b-config-files/ii-analysis-data/site-loc-info/","title":"Location info","section":"Analysis / the data","content":"Location info #  Site location information (site location info), if provided, is used to evaluate spatial autocorrelation in model residuals.\nsite location info:  file: assets/uplands-data/ROMN/LIBI_GRKO_metrics_adjwt_20170414_forCSP.csv  coordinate columns:  - xcoord  - ycoord Here again, we point to the name of the file (file) and supply the names of the columns containing the spatial coordinates (coordinate columns). Note that proper residual analysis requires Cartesian coordinates. If the locations come directly from a geographic coordinate system, they\u0026rsquo;ll need to be transformed to a projected coordinate system.\n"},{"id":17,"href":"/models-for-missing-data/docs/0-getting-started/requirements/","title":"Requirements","section":"Getting started","content":"Requirements #  The requirements include R (v4.X.X) and RStudio (if you\u0026rsquo;d like to work with models-for-missing-data interactively), and JAGS (v4.3.0). Git and Git Bash (for Windows users) are convenient if you\u0026rsquo;d like to stay up to date with the latest changes.\nThe requirements (including a few non-essentials) are described in the latest Dockerfile. You\u0026rsquo;re likely to need everything you see beneath install2.r in the instructions below. You can install these from your R console with install.packages(). FROM rocker/geospatial:4.1.2  # Copy Latin Modern font files to fonts directory and refresh fonts cache. COPY Latin-Modern-Roman-fontfacekit.zip /tmp RUN unzip tmp/Latin-Modern-Roman-fontfacekit.zip -d /usr/share/fonts \u0026amp;\u0026amp; \\  fc-cache -f -v \u0026amp;\u0026amp; \\  rm tmp/Latin-Modern-Roman-fontfacekit.zip  # Install JAGS. RUN apt-get update -y \u0026amp;\u0026amp; apt-get install -y jags  # Graphics and other required packages. RUN apt-get install tree \u0026amp;\u0026amp; \\  Rscript -e \u0026#34;update.packages(ask = FALSE)\u0026#34; \u0026amp;\u0026amp; \\  install2.r --error \\  abind \\  spsurvey \\  hrbrthemes \\  ggthemes \\  ggridges \\  cowplot \\  HDInterval \\  rjags \\  coda \\  R2jags \\  runjags \\  bayesplot \\  extraDistr \\  MCMCpack \\  magick \\  gifski \\  gganimate \\  multidplyr \n"},{"id":18,"href":"/models-for-missing-data/docs/1-guide/c-outputs/output-dir/","title":"The output directory","section":"Outputs","content":"The output directory #  All outputs / logs are sent to the \u0026ldquo;assets\u0026rdquo; folder. Its contents mirror \u0026ndash; almost exactly \u0026ndash; the directory structure of the \u0026ldquo;config\u0026rdquo; folder. The only difference is that the results of analyses for each state variable are stored in separate directories, whereas the configuration of analyses for like-variables (related count or cover variables, for example) can be specified simultaneously in the same YAML file. In other words, there can be many more output directories than analysis config files!\nAt a high level, the directory structure associated with the output of a given model looks like the following:\n. # output root ├── 00-input/ ├── 01-diagnostics/ ├── 02-checking/ ├── 03-inference/ ├── 99-misc/ ├── calling-script.R ├── inits-needed.txt ├── mod-summary.csv ├── model.jags ├── output-metadata.md └── system-time.txt  From the output root (.), there are an ordered / numbered set of directories and several files. The numeric prefix assigned to each directory is intended to provide some indication of the intended sequence by which an analyst would inspect model outputs.\n   File Description     calling-script.R Reproducible calling script   inits-needed.txt List of the parameters for which initial values (inits) are required   mod-summary.csv Test statistics (p_sd, p_mean), posterior predictive loss (ppl), deviance information criterion (dic), and   \\(\\hat{R}\\)  (gelman_diag)   model.jags JAGS model file   output-metadata.md Basic metadata for files included in the output folder   system-time.txt Time required to fit the model    We will work through the contents of each of the directories in turn.\n"},{"id":19,"href":"/models-for-missing-data/docs/1-guide/c-outputs/output-dir/02-checking/","title":"02-checking","section":"The output directory","content":"02-checking | model checking #  Overview #  A suite of graphical and tabular displays for model checking.\n   File Description     op/ Observed vs. predicted plots   ppc/ Graphical displays comparing the observed data to data simulated from the posterior predictive distribution. For mixed models, there will be files for each of the distributions. If the model fits well, we should be able to use it to generate data that looks a lot like the data we have in-hand. Subfolders for outputs by stratum and unit or other grouping variables specified by ppc facets in the analysis config file (see HERE for more).   variography/ Checks for spatial autocorrelation    Subdirectories #  op/ | observed vs. predicted plots #     File Description     op-y-rep.jpg A scatterplot of observed (   \\(y\\)  -axis) vs. the median predicted ( \\(x\\)  ) values. The horizontal lines / whiskers around each point correspond to the 95% HDI for the  \\(y^{rep}\\)  \u0026rsquo;s associated with each observation.    ppc/ | posterior predictive checks #  Graphical displays comparing the observed data to data simulated from the posterior predictive distribution. For mixed models, there will be files for each of the distributions. If the model fits well, we should be able to use it to generate data that looks a lot like the data we have in-hand. Subfolders for outputs by stratum and unit and any other faceting variables specified by ppc facets, as described here.\n   File Description     y-rep-bayes-p-by-stratum_id[unit_code].csv Bayesian p values for mu and sigma by stratum or unit code   y-rep-by-stratum_id[unit_code]-9-draws.jpg Separate histograms of  \\(y\\)  and some ( \\(n=9\\)  ) of the  \\(y^{rep}\\)  datasets   y-rep- by-stratum_id[unit_code]-stats.jpg The distribution of test statistics. The solid, vertical line is the value of the test statistic computed from the observed data,  \\(y\\)  , while the underlying bars represents the distribution of the test statistic in the  \\(y^{rep}\\)  simulations.    variography/ | spatial autocorrelation #     File Description     residuals-df.rds Residuals for each observation. Used as input to variograms.   variograms.png Figure shows degree of spatial autocorrelation in data, semi-variance by distance by direction or by any direction. Note that the default is to evaluate up to 1/3 of the total distance represented in the data.    "},{"id":20,"href":"/models-for-missing-data/docs/1-guide/c-outputs/output-dir/03-inference/","title":"03-inference","section":"The output directory","content":"03-inference | model inference #  Overview #  Tabular and graphical summaries of Markov chain Monte Carlo (MCMC) draws from the posterior distribution of the parameters of a Bayesian model. The asterisk corresponds to the coefficients.\n   File Description     coef/ Model coefficients   me/ Marginal effects   park/ Park-level inference   site/ Site-level inference   strata/ Stratum-level inference   zone/ Zone-level inference   coda-samples-quantiles.csv Quantiles of the posterior distribution of key variables / parameters   coda-samples-summary.txt Descriptive statistics and quantiles of the posterior distribution of key variables / parameters    Subdirectories #  coef/ | model coefficients #     File Description     additional-coef-estimates-Beta-untransformed.png The posterior distribution of fixed effect (covariate) terms.   beta-coef-estimates-untransformed.png The median (points) and 95% equal-tailed credible intervals for group-level (random) effects. When the model is b0 only the intercepts (   \\(\\beta_{0j}\\)  ) will vary by site within each stratum. When the model is b0-b1 both intercept ( \\(\\beta_{0j}\\)  ) and time-slope terms ( \\(\\beta_{1j}\\)  ) will vary by site (with correlation  \\(\\rho\\)  ).   hypers-hist-*.png The hyper-distribution of random intercepts (\u0026ldquo;hypers-hist-B0.png\u0026rdquo;) or random time-slope terms (\u0026ldquo;hypers-hist-B1.png\u0026rdquo;) for each stratum    park/ | park-level inference #  Park-level mean of the response over time. Subfolders include results for all possible sites (\u0026ldquo;all\u0026rdquo;) and sampled sites (\u0026ldquo;sampled\u0026rdquo;). Unless you have provided covariates for all sites, inference with covariates (the pred files) will be limited to sampled sites.\nIn the file names below, the first asterisk corresponds to either hat or pred. The hat files hold any covariates present at their mean (essentially removing \u0026ndash; or controlling for \u0026ndash; the effect of changes in the covariates over time). The pred files (if present) correspond to predictions of park-level means conditional on the actual time-varying values of covariates \u0026ndash; AKA \u0026ldquo;bumpy plots.\u0026rdquo; The uncertainty intervals, sometimes called \u0026ldquo;credible intervals\u0026rdquo;, are derived using the 95% Highest (Posterior) Density Intervals, by default (dotted black lines). The median is shown in the solid black line. If \u0026ldquo;out of sample\u0026rdquo; (oos) JAGS objects, exist, results are provided both for the expected value (i.e., for the mean) of new observations as well as the value of new observations themselves (Citation: Hobbs\u0026#32;\u0026amp;\u0026#32;Hooten,\u0026#32;2015,\u0026#32;p.\u0026nbsp;197Hobbs,\u0026#32; N.\u0026#32;\u0026amp;\u0026#32;Hooten,\u0026#32; M.\u0026#32; (2015). \u0026#32;Bayesian models. \u0026#32; Princeton University Press. ) .\n   File Description     *-park-mean-annual-summary-hdi95.csv Annual estimates of status (median, lower and upper credible intervals).   *-park-mean-plot-hdi95.jpg Graphical representations of the RDS file. In the figures, the semi-transparent thin lines are draws from the posterior distribution of the park-level mean; the thick, solid dark line is the median of the mean and the thick, dashed lines correspond to the 95% HDIs at each timestep.   *-park-mean-plot-objects-hdi95.rds The data required to reproduce the plot.    References #    Hobbs\u0026#32;\u0026amp;\u0026#32;Hooten (2015)  Hobbs,\u0026#32; N.\u0026#32;\u0026amp;\u0026#32;Hooten,\u0026#32; M.\u0026#32; (2015). \u0026#32;Bayesian models. \u0026#32; Princeton University Press.     "},{"id":21,"href":"/models-for-missing-data/docs/2-best-practices/","title":"Best practices","section":"Docs","content":"Best practices #  Below, we present a generalized workflow for using this model API. Ideally, you\u0026rsquo;ve got some expertise or experience working with the data you\u0026rsquo;re interested in modeling. Perhaps you know the ecological system, and may even have some sense for what the likely drivers of change or trend might be.\nExploratory data analysis #  The response data #  We recommend taking a look at basic histograms of your response variable. If you don\u0026rsquo;t know already, this is a great time to think about why type of data you\u0026rsquo;re working with. Is it a count, a proportion, or some other quantity? Look for signs of skewness or zero-inflation.\nThe covariates #  It may be helpful to evaluate the correlation between covariates and your response variable, and among covariates. Scatterplots of the response variable vs. each covariate can sometimes be illuminating. If two potential covariates are highly corelated, one should probably be dropped in favor of the other to ensure parsimony, model convergence, and sensible results.\nExisting analysis config files as templates #  If your data type is similar to one of the demo datasets, it may make sense to create a copy of that analysis config file and modify it according to your needs.\nModel checking and evaluation #  We recommend checking model convergence before doing anything else.\nFailure to converge #  If a model is failing to converge, it can be for all sorts of reasons. Sometimes there simply weren\u0026rsquo;t enough MCMC iterations, or your inits were out of left field. If convergence issues affect specific parameters, it can be helpful to play around with different model parameterizations. Sometimes there\u0026rsquo;s not enough trend of any sort to permit a random intercept / random slopes (b0-b1) model, for instance. (This can be verified by plotting the empirical means at each site over time, for example.) If you\u0026rsquo;re seeing extreme \u0026ldquo;funnel\u0026rdquo; shapes in the funnel diagnostics, it may be helpful to try a non-centered parameterization. In yet other cases, it might be the prior(s). You can check if it\u0026rsquo;s the priors by rerunning specific models (\u0026ldquo;model.jags\u0026rdquo; with modified priors) using the output directory and associated \u0026ldquo;calling-script.R\u0026rdquo;.\nPoor Bayesian p values #  If a Baysian p value obtained from a posterior predictive check is close to either 0 or 1 (e.g. outside of 0.2-0.8), then this is a sign that your model was not able to achieve a good fit to the data. Some common causes of this include unmodeled variance (either via covariates, random effects, or accomodating overdispersion), or a poor match between the chose likelihood distribution and the actual distribution of the process. For example, if your data were zero-inflated, but your chosen likelihood didn\u0026rsquo;t accomodate this, then your model will likely produce data with a positive bias, resulting in a Bayesian p value for the mean of the data being closer to 0. Alternatively, if your data are overdispersed but you chose a Poisson distribution for the likelihood, then your model predictions for variance will be biased low, resulting in a Bayesian p value for the variance being closer to 1. Whenever a posterior predictive check fails, it is good practive to revisit the distributional assumptions about both the data and the process models you used.\n"},{"id":22,"href":"/models-for-missing-data/docs/1-guide/b-config-files/ii-analysis-data/covariate-info/","title":"Covariate info","section":"Analysis / the data","content":"Covariate info #  Covariate information (covariate info), if provided, is joined to the response information prior to model fitting. It\u0026rsquo;s used only in models for which predictors are specified.\ncovariate info:  file: assets/uplands-data/ROMN/LIBI_Covariates_AllSitesAllYears_20201104_Through2016_with_exotics.csv  event date info:  date-time column: Year  date-time format: Y! As with the other statements in the data block, we point to the name of the covariate file (file; see the covariate data section for more detail) and, if different from the date attributes in the response data, supply info required to properly parse covariate datetime fields.\n"},{"id":23,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iii-analysis-model/group-level-effects/","title":"Group-level effects","section":"Analysis / the model","content":"Group-level effects #  The basic motivation for random group-level effects is that sites matter. They are an essential feature of the sampling design. Having no such random effects would imply that sites don\u0026rsquo;t matter and observations can be pooled (as if they were collected from a completely random sample).1\nGroup-level effects incorporate differences among sites (that may be impossible to model with covariates) to inform park-level trends. They allow each site to have its intercept (and potentially, its slope) drawn from a common / underlying distribution of intercepts (and slopes). We make inference at the park scale using the parameters of the distribution from which the individual site intercepts and slopes are drawn.\nSyntax #  group-level effects:  - b0  - b0-b1 Usage #  In cases where you specify multiple group-level effects, the model API will create a separate analysis for each, and the relative performance of each can be evaluated using model diagnostics, posterior predictive checks, and information criteria.\nOptions #  The usual case #     Option Description Use case     b0 Random intercept    b0-b1 Correlated random intercept and random time slope    none No random effects, intercept and time slope terms are fixed Used only when a model includes terms (e.g., for management zone) that create strong, irresolvable identifiability problems for the default group-level effect terms    For hurdle-ordinal-latent-beta models #  The beta-hurdle model adds an additional group-level effects statement called group-level effects (zeros). This statement controls group-level effects on the occurrence process (the hurdle).\n   Option Description Use case     g0 Random intercept for occurrence    g0-g1 Correlated random intercept and random time slope for occurrence       Although the mean over time predicted by a pooled and a hierarchical model may not differ substantially, the pooled model fails to properly represent uncertainty. This problem is espcially pronounced when there are conflicting trends among sites, which a pooled model inappropriately ignores.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":24,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iv-analysis-extras/marginal-effects/","title":"Marginal effects","section":"Analysis / extras","content":"Marginal effects #  Summaries of the association between a change in a regressor and a change in the response variable.\nSyntax #  drivers: true Usage #  When drivers: true, the model API creates additional JAGS objects, which are used to evaluate the marginal effects of explanatory variables in the model. By default, it shows the effect of each variable over its empirical range, holding all other variables at zero (the mean of scaled continuous variables or the reference level of categorical variables).\n.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#444;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative} Note\nThe behavior of drivers: true depends on the type of variable. The effects of continuous variables are shown on their original scale. The effect of indicator variables is shown on a 0-1 scale. Interaction terms are (perhaps unhelpfully) left in scaled form, and require additional work to plot properly. See this write-up for more!\n There is an additional, optional statement called crossings that can be called alongside drivers to evaluate different combinations of explanatory variables. For instance, if we are interested in the effect of   \\(x_1\\)  not just at the mean of  \\(x_2\\)  (i.e., when  \\(x_2=0\\)  ), but when  \\(x_2=\\mathrm{min}(x_2)\\)  or  \\(x_2=\\mathrm{max}(x_2)\\)  , we would specify:\ndrivers: true crossings:  - min_seen  - zero  - max_seen Warning\nWe do not recommend using crossings unless that specific line of inference is needed, as it can drastically increase model run times and the size of the model object.\n "},{"id":25,"href":"/models-for-missing-data/docs/0-getting-started/quickstart/","title":"Quickstart","section":"Getting started","content":"Quickstart #  Assuming you\u0026rsquo;ve got the models-for-missing-data project code (see Installation) and have all of the dependencies (see Requirements), the last remaining pieces you\u0026rsquo;ll need to begin running models are the data and analysis config files. We\u0026rsquo;ve included examples of each in the \u0026ldquo;assets/\u0026rdquo; directory. See the guide for more information about each of these components of the models-for-missing-data workflow. You can find an example of the data here, and an analysis config file for these data here.\nUsage #  There are two basic ways to call models-for-missing-data for analyses: interactively using RStudio or non-interactively via the command line.\nGraphical user interface (RStudio) #  Start RStudio and set your working directory to the project directory. Open the template \u0026ldquo;analysis-pipeline.R\u0026rdquo;, which lives in \u0026ldquo;model-api/\u0026rdquo;. If you\u0026rsquo;d like to make changes to \u0026ldquo;analysis-pipeline.R\u0026rdquo;, or begin running models with your own data, create a copy of \u0026ldquo;analysis-pipeline.R\u0026rdquo; by appending \u0026ldquo;local\u0026rdquo; or your initials as a suffix. E.g., \u0026ldquo;analysis-pipeline-local.R\u0026rdquo;.\nCommand line interface (CLI) #  Run an analysis utilizing 2 CPUs with, for example:\n./model-api/analysis-pipeline.R \\  assets/_config/M4MD/ELDO/counts.yml \\  --n-adapt 5000 --n-update 50000 --n-iter 15000 \\  --n-cores 2 See ./model-api/analysis-pipeline.R --help for more details on all CLI arguments, options, and flags.\n"},{"id":26,"href":"/models-for-missing-data/docs/1-guide/a-data/iii-types-of-random-variables/","title":"Types of random variables","section":"Data","content":"Types of random variables #  Understanding the type of data you are working with will be extremely important as we begin to define models. An important term to introduce at this point is variable support. The support of a variable describes the types of values that individual observations can assume. When modeling a random variable, you must choose a probability distribution with the same support. Arguably the most prevalent and useful probability distribution is the normal distribution, which has \u0026ldquo;real\u0026rdquo; support, meaning that it can take on any value from   \\(-\\infty\\)  to  \\(\u0026#43;\\infty\\)  . In many cases, variables in the real world can\u0026rsquo;t take on negative values (e.g., tree height), so the researcher must transform them (e.g., by taking the natural log) prior to fitting models if they wish to use a normal distribution. This isn\u0026rsquo;t always necessary, however, as there are some probability distributions, such as the gamma and lognormal, that have support for continuous values greater than 0, so they will work with variables with matching support \u0026ldquo;out of the box\u0026rdquo; without any need for transformation prior to model fitting. In ecology, some variables, typically proportions, can have 0-1 support, meaning that they can take on any value between 0 and 1, including 0 and 1. A beta distribution can be used to model this type of variable.\nIn addition to continuous random variables, there are also discrete random variables, which are typically used to describe counts. Some counts, such as population, can take on any integer greater than or equal to 0. A Poisson or negative binomial distribution can be used to model these variables. Other counts, for example the number of visits out of a total of  \\(N\\)  in which an animal was observed, have a maximum value. In these cases a binomial distribution can be used which can take on any number between and included 0 and  \\(N\\)  . The last common discrete variable in ecology is a binary one, in which the response can be either 0 or 1 (e.g., presence of a species within a plot). For these variables, the Bernoulli distribution can be used.\nMore details on different probability distributions are shown in the tables below. Click on the images to display an enlarged version in a new tab in your web browser.\nContinuous random variables #    Discrete random variables #    True or extra zeros #  There are occasions when we need to accommodate \u0026ldquo;true\u0026rdquo; zeros or extra zeros. In these cases, we need to use either hurdle or zero-inflated models. From wikipedia:\n Hurdle models differ from zero-inflated models in that zero-inflated models model the zeros using a two-component mixture model. With a mixture model, the probability of the variable being zero is determined by both the main distribution and the mixture weight. We\u0026rsquo;ll see references to these types of models as we begin to talk about specific likelihood functions.\n "},{"id":27,"href":"/models-for-missing-data/posts/unequal-inclusion-probability/","title":"Unequal inclusion probabilities","section":"Posts","content":"The Sonoran Desert is among the most extreme environments on Earth. Sampling in these remote, rugged landscapes requires a different approach. When the Park Service established monitoring in Organ Pipe Cactus National Monument they used an approach to select sites based on the cost of travel to sites on the broader landscape, visiting less \u0026ldquo;costly\u0026rdquo; sites with higher probability than more costly sites. The cost surface that defined the probability of inclusion of sites was developed using terrain data, and a tool that estimates the time to travel to any arbitrary location on the landscape.\n"},{"id":28,"href":"/models-for-missing-data/docs/1-guide/c-outputs/output-dir/99-misc/","title":"99-misc","section":"The output directory","content":"99-misc | model miscellany #  Miscellaneous outputs.\n   File Description     z-jags.rds JAGS model object   zones     "},{"id":29,"href":"/models-for-missing-data/docs/3-faq/","title":"FAQ","section":"Docs","content":"Frequently asked questions #  Q: Which type of data am I working with?\nA: Let\u0026rsquo;s talk about it!\nQ: Do we use stratum weights when we do the finite population correction? A: Yes.\nQ: Should the locations I supply be for sites or samples within sites? A: For now, just the site centroids.\nQ: Why do my variography plots show only a fraction of the largest distance between sites?\nA: The R functions we are using to develop these plots only show semivariance for distances up to 1/3 of the maximum observed distance.\n"},{"id":30,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iv-analysis-extras/ppc-facets/","title":"Posterior predictive checks","section":"Analysis / extras","content":"Posterior predictive checks #  By default, the posterior predictive checks produced by the model API include stratum_id and unit_code. We include these elements by default because they correspond directly to subscripts in the model. You can specify additional variables for post-hoc model checking via ppc facets. Performing posterios predictive checks is an essential step in modeling process. These checks essentially allow you to evaluate whether your model can generate new data that are similar to your observed data. The posterior predictive check process involves generating many new data sets from your model from what is called the posterior predictive distribution, and comparing charateristics (e.g. the mean and/or variance of the data set) of those simulated data sets those same characteristics of data used for model fitting. If you have a very good model that fits your data well, then in the case of the mean, you should expect the true mean of your data set to fall right around the 50th percentile of the distribution of means from the simulated datasets (the same goes for variance or other quantites). A posterior predictive check identifies this quantile (which is often referred to as a Bayesian p value). A Bayesian p value that is very close to 0 or 1 (a rule of thumb that is often used is greater than 0.8 or less than 0.2) may suggest a poor model fit.\nSyntax #  ppc facets:  - cal_year Usage #  Values under ppc facets correspond to columns from the original response or covariate data. When supplied, the output directory will include additional checks. In the example above, you would see a folder named \u0026ldquo;ppc/cal_year\u0026rdquo; appear beneath \u0026ldquo;02-checking\u0026rdquo; with \u0026ndash; in this case \u0026ndash; test statistics for each calendar year.\n"},{"id":31,"href":"/models-for-missing-data/posts/sampling-and-populations/","title":"Sampling and populations","section":"Posts","content":"We sample for a very practical reason. It\u0026rsquo;s usually impossible to get information on the whole population, so we use a sample to make inferences about the population. In our case, the population is typically all sites in a stratum or all sites \u0026ndash; in all strata \u0026ndash; at the scale of an entire park. Typically, the inference we seek entails three questions.\n What\u0026rsquo;s the best estimate of the population mean?   We can generate a sample mean,   \\(\\bar{x}\\)  , from our sample. This is the best estimate of the population mean.\n  \\[\\bar{x}=\\frac{\\sum{x}}{n}\\]  How confident are we about that estimate?   Because we have a small sample, we can\u0026rsquo;t be sure the sample mean is exactly the population mean. There\u0026rsquo;s uncertainty around that estimate. The standard error of the sample mean,  \\(\\text{SE}(\\bar{x})\\)  , relates to how uncertain we are about our estimate. The higher it is, the more uncertain we are that our sample mean reflects the true population mean. Small samples generally yield larger standard errors.\n  \\[\\text{SE}(\\bar{x})=\\frac{s}{\\sqrt{n}}\\]  What is our best estimate of the population standard deviation?1   The sample standard deviation,  \\(s\\)  , can give us information about the possible population standard deviation \u0026ndash; how spread the population is likely to be with respect to the measure of interest.\n  \\[s=\\sqrt{\\frac{\\sum{(x - \\bar{x})^2}}{n-1}}\\]  These three measures form the basic substrate of our understanding of the populations we are sampling, and are all essential to decision making.\nBelow, we consider three scenarios, sampling from an infinite population, a finite population, and the full population. The goal of the examples below is to show what sampling is all about. As we shall see, the finite population case is the bridge between the other two edge cases \u0026ndash; the infinite and full population instances.\nAn infinite population #  This is a very typical scenario. Of course, I\u0026rsquo;m not aware of any truly infinite populations. What we mean, instead, is that our sample of the population,  \\(n\\)  , is small enough that\u0026hellip; blah blah blah. As such, we can think of the population as at least theoretically infinite.\nExample Estimate the average number of trees in sites #  Given a sample of  (n=5)  sites with observations\u0026hellip;, the sample mean is XX. This our best estimate of the true population mean. But what is the population we are referring to? Well, it\u0026rsquo;s all possible sites. Of course, there\u0026rsquo;s not an infinite number of sites, but it\u0026rsquo;s large enough that we can treat it as though it is infinite. How confident are we in this estimate? If we took a different sample, the sample mean would be different, but how different? This is where the standard error of the sample mean comes in\u0026hellip;   A finite population2 #  Not particularly common, but it\u0026rsquo;s useful to look at because it ties together both the infinite population situation and the final example.\n \\[\\text{SE}(\\bar{x})=\\frac{s}{\\sqrt{n}}\\sqrt{\\frac{N - n}{N - 1}}\\]  The standard error of the mean in this case will be less than in the infinite population case, because we have proportionately more information about the population that we do in the first example.\nThe full population #  Technically no longer a sample. We have the full population in hand. There\u0026rsquo;s no observations that site outside of the sample that we care about.\n \\[\\mu=\\frac{\\sum{x}}{N}\\]  How confident are we in this estimate? Perfectly confident:  \\(\\text{SE}(\\mu)=0\\)  ! Why? We can still think of this as a sample from a finite population, but the number of observations in the sample equals the number of observations in the population. The formula for the standard error of the mean for a finite population still applies. The numerator in the second term  \\(N-n\\)  becomes zero, and the whole thing collapses to zero.3\nWe can find the population standard deviation.\n \\[\\sigma=\\sqrt{\\frac{\\sum{(x - \\mu)^2}}{N}}\\]    Note that part of the  \\(\\text{SE}(\\bar{x})\\)  is in fact  \\(s\\)  .\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Sometimes called \u0026ldquo;sampling without replacement\u0026rdquo;.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Note that the same basic reasoning can be applied to the first example, as well. If we were to look at an infinite population and sub in Inf for the capital Ns. The second term resolves to 1. Inf on inf is going to be 1, the sqrt of which is also 1, so the second term dissapears and you\u0026rsquo;re left with the original formula for the standard error.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":32,"href":"/models-for-missing-data/docs/0-getting-started/sync-changes/","title":"Sync changes","section":"Getting started","content":"Sync changes #  Checking for updates #  Project updates #  To get the latest models-for-missing-data code, navigate to your project directory using a terminal, and run git pull.\nSubmodule updates #  First, be sure to do any necessary housekeeping (remove, stash, or commit changes). To get the latest updates for each of the submodules, run:\ngit submodule update --recursive --remote If you encounter an error, it\u0026rsquo;s likely you\u0026rsquo;ve made changes locally that are not yet saved (staged and committed using git add and git commit). Git won\u0026rsquo;t replace changes in uncommitted files with changes on the remote by default. This is desirable behavior. Try committing your changes locally before syncing with the remote.\nPushing local changes to a submodule to its remote #  First, cd into the submodule directory. We\u0026rsquo;re going to do all of our Git work within the context of the submodule. If you\u0026rsquo;ve got uncommitted changes, do any necessary housekeeping:\ngit status git add . git commit -m \u0026#34;\u0026lt;some descriptive message about your changes\u0026gt;\u0026#34; As always, please ensure you\u0026rsquo;re not staging / committing unwanted files (e.g., binary files). Then run:\ngit fetch git checkout gh-submodule git merge \u0026lt;ref\u0026gt; git push origin gh-submodule Troubleshooting #  If, on an attempt to pull from the remote submodule, you got fatal: Not possible to fast-forward, aborting, try:\ngit merge origin/\u0026lt;submodule\u0026gt; "},{"id":33,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iii-analysis-model/variances/","title":"Variances","section":"Analysis / the model","content":"Variances #  As with group-level effects for the intercept or time slope terms, each site can also have its own variance.\nSyntax #  variances:  stratum-level fixed:  level: stratum  type: fixed  response column(s):  - native.rich  - native.forb.rich  site-level hierarchical:  level: site  type: hier  response column(s):  - native.rich  - native.forb.rich Usage #  The entries beneath response column(s) have to be column names, not variable descriptions. The model API will create all combinations of models specified in these blocks. Thus, in the example above, we would obtain four distinct models.\nIf the variances statement is omitted altogether, the default behavior of the model API is to fit a model with fixed stratum-level variances. In other words, observations from all sites within a stratum are assumed to have the same variance.\nNote that the parameterization for the variances of observations depends on the probability distribution being used. In the Poisson, for instance, the mean equals the variance. If there are hierarchical terms in the model for the mean, then in some sense the variance is also hierarchical, but there is no option to model the variances independently of mean.\n"},{"id":34,"href":"/models-for-missing-data/docs/1-guide/d-worked-examples/","title":"Worked examples","section":"Guide","content":"Worked examples #  In all cases below we will work with the demo data included with models-for-missing-data, which has the following directory structure:\n. └── assets └── _config/ └── M4MD/ ├── ELDO/ │ ├── _park-level-attributes.yml │ ├── counts.yml │ └── hits-vs-trials.yml └── _network-level-attributes.yml  A minimal example for count data #  The following example comes from \u0026ldquo;assets/_config/M4MD/ELDO/counts.yml\u0026rdquo;.\nThe analysis config file #  # ==== DATA ===================================================================  response info:  file: assets/_data/count-data.csv  state variable:  response column:  - y_sim  description:  - Simulated count data  sampling method: plot  sample id column(s):  - plot  site location info:  file: assets/_data/sample-locs.csv  coordinate columns:  - x_coord  - y_coord  covariate info:  file: assets/_data/sample-covariates.csv  # event date info: # TODO: describe. Only use when covariates are time-varying!  # date-time column: event_year  # date-time format: Y!  # ==== MODEL ==================================================================  # Likelihood. For counts, one or both of: poisson, negative-binomial. likelihood:  - poisson  - negative-binomial  # Deterministic model for the mean. For counts, one of: exponential, linear, # or monomolecular. deterministic model:  # - linear  - exponential  # - monomolecular  # Group-level effects structure. One of: b0, b0-b1. group-level effects:  - b0  # - b0-b1  # Variance structure (these *have* to be colnames, not descriptions). variances:  stratum-level fixed:  level: stratum  type: fixed  response column(s):  - y_sim  # site-level hierarchical:  # level: site  # type: hier  # response column(s):  # - y_sim  # Covariates. additional covariates:  - w1  # Initial values (one of: \u0026#39;auto\u0026#39;, \u0026#39;default\u0026#39;, or \u0026#39;inherited\u0026#39;) initial values: default  The model call #  You can run this model interactively from RStudio using \u0026ldquo;model-api/analysis-pipeline.R\u0026rdquo;, or at the command line with:\n./model-api/analysis-pipeline.R \\  assets/_config/M4MD/ELDO/counts.yml \\  --n-adapt 5000 --n-update 10000 --n-iter 8000 \\  --n-cores 2 \\  --excl-null Note that we exclude the \u0026ldquo;null\u0026rdquo; (time-only) model with the flag --excl-null.\nSelected outputs #  Convergence diagnostics #  Potential scale reduction factors:   Point est. Upper C.I. B1[1] 1.00 1.01 B1[2] 1.00 1.00 Beta 1.00 1.01 deviance 1.00 1.00 mu.B0[1] 1.00 1.00 mu.B0[2] 1.00 1.00 p.mean 1.00 1.00 p.sd 1.00 1.00 sigma.B0[1] 1.00 1.01 sigma.B0[2] 1.01 1.01  #  Model checking and evaluation #     Posterior predictive checks Observed vs. predicted plots            Inference #     Intercept and time slope terms Fixed effects            A minimal example for binomial data #  The following example comes from \u0026ldquo;assets/_config/M4MD/ELDO/hits-vs-trials.yml\u0026rdquo;.\nThe analysis config file #  # ==== DATA ===================================================================  response info:  file: assets/_data/binomial-data.csv  state variable:  hits column:  - y_sim  description:  - Simulated binomial data  trials column:  - trials  sampling method: transect  sample id column(s):  - transect  site location info:  file: assets/_data/sample-locs.csv  coordinate columns:  - x_coord  - y_coord  covariate info:  file: assets/_data/sample-covariates.csv  # event date info: # TODO: describe. Only use when covariates are time-varying!  # date-time column: event_year  # date-time format: Y!  # ==== MODEL ==================================================================  # Likelihood. For counts, one or both of: poisson, negative-binomial. likelihood:  - binomial  - beta-binomial  # - zero-inflated-binomial  # - zero-inflated-beta-binomial  # Deterministic model for the mean. For counts, one of: exponential, linear, # or monomolecular. deterministic model:  - inverse-logit  # Group-level effects structure. One of: b0, b0-b1. group-level effects:  - b0  # - b0-b1  # Variance structure (these *have* to be colnames, not descriptions). variances:  stratum-level fixed:  level: stratum  type: fixed  response column(s):  - y_sim  # site-level hierarchical:  # level: site  # type: hier  # response column(s):  # - y_sim  # Covariates. additional covariates:  - w1  # Initial values (one of: \u0026#39;auto\u0026#39;, \u0026#39;default\u0026#39;, or \u0026#39;inherited\u0026#39;) initial values: default  "},{"id":35,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iii-analysis-model/covariates/","title":"Covariates","section":"Analysis / the model","content":"Covariates #  The predictors to use for modeling the mean of the response variable.\nSyntax #  additional covariates:  - Botanist (JA)  - Botanist (JA), deficit.pregr Usage #  For categorical variables (e.g., Botanist), the optional parenthetical declaration can do one of two things.\n It sets the reference level for dummy-coded variables. In the case of Botanist (JA), the reference level becomes the botanist with initials JA. If not specified, the reference level will be set using R\u0026rsquo;s default handling for factors (using the first level of the factor sorted in ascending alphabetical o.rder as the reference level) It can also be used to implement sum-to-zero effect coding, which we call deflections. For instance MgmtZone (deflections). In the case of deflections, the coefficients for each level of the categorical variable sum to zero. By default the model returns only the first   \\(k-1\\)  coefficients, but the  \\(k^{\\mathrm{th}}\\)  coefficient can be computed as a derived quantity. See this StackExchange post for more on this calculation.  See this resource for additional background on dummy vs effect coding.\nInteraction terms can be specified using \u0026ldquo;star\u0026rdquo; notation. So a Botanist (JA), deficit.pregr specification would produce a botanist-by-deficit interaction term. Note that there is no automatic expansion for the main effects, so a more complete specification would entail something like the following:\nadditional covariates:  - Botanist (JA), deficit.pregr, Botanist (JA) * deficit.pregr "},{"id":36,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iv-analysis-extras/trend-step-size/","title":"Trend step size","section":"Analysis / extras","content":"Trend step size #  The increment (in units of years) by which the hat-type means are evaluated.\nSyntax #  trend step size: 1 # (0, 1] Usage #  The default trend step size is 0.2 years, which means we get five predictions in every calendar year. For instance, between years 0 and 1, this equates to predictions at 0.0 0.2 0.4 0.6 0.8 1.0  This yields hat-type means that appear very smooth, especially when the trend is curvilinear. Increasing the step size saves computation time (and the size of in-memory JAGS objects), but at the cost of a smooth trend line. Consider the following:\n The teal line corresponds to a trend step size of 1, while the salmon-colored line corresponds to the default trend step size. The larger trend step size gives the false impression that the change in the mean is stepwise linear, when in fact it is not. If using a larger trend step size to fit \u0026ldquo;lighter\u0026rdquo; models more quickly, this is worth bearing in mind.\n% mutate(mu = boot::inv.logit(-0.5 + -1 * x), `trend step size` = increment) d % bind_rows(d_raw %% filter(x %% 1 == 0) %% mutate(`trend step size` = 1)) ggplot(d) + geom_line(aes(x = x, y = mu, color = factor(`trend step size`)), size = 0.8) + theme_ipsum_rc( grid = \"Y\", base_size = 16, axis_title_size = 18, strip_text_size = 18 ) + labs(x = expression(x), y = expression(italic(mu))) + theme(axis.title.y = element_text(angle = 0)) + guides(color = \"none\") ggsave('docs/website/content/docs/1-guide/b-config-files/iv-analysis-extras/trend-step-size.png', width = 7, height = 5) -- "},{"id":37,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iv-analysis-extras/exposure/","title":"Exposure / offset","section":"Analysis / extras","content":"Exposure / offset #  "},{"id":38,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iii-analysis-model/inits/","title":"Initial values","section":"Analysis / the model","content":"Initial values #  Initial values determine the starting point of the sampler, and can play a large role in ensuring efficient sampling and convergence. Implementing some degree of randomness is also important when defining initial values to ensure that a model is able to converge properly for a range of initial values. Providing initial values that are within or near the posterior distribution of the parameter of interest serves not only to speed up convergence, but also to optimize the efficiency of the sampler (i.e. make it more random and less autocorrelated) in cases when the sampling algorithm is doing hyperparameter tuning during the early phases of sampling.\nSyntax #  # Initial values (one of: \u0026#39;none\u0026#39;, \u0026#39;default\u0026#39;, or \u0026#39;inherited\u0026#39;) initial values: inherited Usage #  A value of none leads to JAGS using NULL inits, while default attempts to use a set of relatively functional anonymous inits. inherited uses defaults at first, and then caches posteriors as inits for subsequent fits. In the case of the beta-hurdle model, there is one additional optional value, empirical, that can be specified.\nIt is also possible to supply a file to inherited values with your own inits.\n"},{"id":39,"href":"/models-for-missing-data/posts/interpreting-coefficients/","title":"Interpreting coefficients","section":"Posts","content":"Making sense of the effects of variables included as predictors #  Some aspects of covariate effects are readily apparent \u0026ndash; for instance, the sign of a coefficient in a model says at least something about the general directionality of the effect, positive or negative. However, a deeper understanding of a model typically requires inferences that go well beyond simple measures of the directionality or significance of effects \u0026ndash; it requires understanding the size of effects.\nWhat do we mean by effect size, and how is it measured? In order to offer a working definition of effect size, we need to use a bit of math. The size of an effect can be approximated as the average change in the response variable being modeled, per unit change in some predictor variable, which we\u0026rsquo;ll call   \\(x_1\\)   \\[\\mu_i = g(\\beta_0 \u0026#43; \\beta_1 x_{1i}).\\]  The parameter  \\(\\beta_0\\)  is the intercept and  \\(\\beta_1\\)  is the slope associated with covariate  \\(x_1\\)  in a generalized linear model (linear, exponential, or inverse logit), which we represent using the link function  \\(g()\\)  . The effect of  \\(x_1\\)  translates into changes in the mean of the response variable through  \\(\\beta_1\\)  and link function  \\(g()\\)  . To understand the effect that  \\(x_1\\)  will have on the mean on the scale of the actual data, we first have to take note of the function for which  \\(g()\\)  is a placeholder, as well as any transformations (e.g., scaling) that may have been applied to the data.\nExample | the response of plant cover to rainfall #  Let\u0026rsquo;s consider a covariate that we might expect to have a mechanistic influence on plant cover, such as accumulated spring precipitation. Thus,  \\(x_1\\)  is a measure of rainfall. The plant cover observations were collected at point intercepts along a transects at a site, indexed by subscript  \\(i\\)  . At any given point intercept, plants are either present or absent.  \\(y_i\\)  , then, is the sum of the number of times plants were detected (the total number of \u0026ldquo;hits\u0026rdquo;) at any point intercept along a transect. The observations are modeled as\n \\[\\begin{align*} p_i \u0026amp;= \\text{logit}^{-1}(\\beta_0 \u0026#43; \\beta_1 x_{1i}) \\\\ y_i \u0026amp;\\sim \\text{binomial}(n, p_i) \\end{align*}\\]  where  \\(n\\)  is the total number of point intercepts evaluated along each transect (the number of \u0026ldquo;trials\u0026rdquo;).  \\(x_1\\)  is scaled from its original units (cm) to zero mean and unit variance prior to fitting the model.\nLet\u0026rsquo;s also take as a given that the estimated median value of the coefficients is as follows:  \\(\\beta_0=0.12\\)  and  \\(\\beta_1=0.22\\)  . Prior to scaling,  \\(x_1\\)  had mean 20.4, standard deviation 15.3, and range [0.4, 70.9]. To better understand the influence of  \\(x_1\\)  on the mean plant cover, we will create a new vector called  \\(x_1^{\\text{pred}}\\)  , which consists of scaled rainfall values at equally spaced intervals over the range of  \\(x_1\\)  . Here is the basic setup, in  \\(\\textsf{R}\\)  :\nb0 \u0026lt;- 0.12 # the intercept b1 \u0026lt;- 0.22 # the effect of spring precipitation  x1_mean \u0026lt;- 20.4; x1_sd \u0026lt;- 15.3; x1_range \u0026lt;- c(0.4, 70.9) x1_pred_raw \u0026lt;- seq(x1_range[1], x1_range[2], length.out = 100) x1_pred \u0026lt;- (x1_pred_raw - x1_mean) / x1_sd Let\u0026rsquo;s plot mean plant cover, p, over the range of x1_pred:\np \u0026lt;- boot::inv.logit(b0 + b1 * x1_pred) p_x1_mean \u0026lt;- boot::inv.logit(b0) # p at average precip plot(x1_pred_raw, p, ylim = c(0, 1), type = \u0026#39;l\u0026#39;, col = \u0026#39;red\u0026#39;) abline(v = x1_mean, lty = 2, col = \u0026#39;gray\u0026#39;) abline(h = boot::inv.logit(b0), lty = 2, col = \u0026#39;gray\u0026#39;) Mean plant cover increases as a function of spring rainfall, from a value of approximately 0.46 at its minimum (next to zero precipitation) to 0.70 at its maximum (~71 cm of rainfall). We can interpret the quantity  \\(\\text{logit}^{-1}(\\beta_0)=\\text{logit}^{-1}(0.12)=0.53\\)  (the horizontal dashed gray line) as the mean site-level cover of plants in a year with average spring rainfall (vertical dashed gray line).1\n This being an inverse logit model, we are somewhat obligated to talk about odds, which are given by the quantity  \\(\\frac{p}{(1-p)}\\)  . In this example, it\u0026rsquo;s the ratio of the probability of a plant being present at a given point intercept to the probability of a point intercept not touching a plant. In a year with average spring rainfall, you are ~1.13X more likely to see it than not (0.53 / (1 - 0.53)).2\n \\(\\beta_1\\)  is the multiplicative change in odds per standard deviation spring precipitation.3 To compute the odds of seeing plant cover if spring rainfall is one standard deviation higher than average we would use\n(odds_x1_mean \u0026lt;- p_x1_mean / (1 - p_x1_mean)) exp(b1) * odds_x1_mean # 1.4 At 1.4X, the odds of encountering plants has gone up. Basically, when rainfall is one standard deviation over the mean, you\u0026rsquo;re now 1.4X more likely to see it than not. Thus, the odds of seeing plants increases with increasing precipitation. We can show the same thing using slightly different math.\np_x1_sd1 \u0026lt;- boot::inv.logit(b0 + b1 * 1) # let\u0026#39;s make sure we can recover the same odds using different math p_x1_sd1 / (1 - p_x1_sd1) # again, 1.4! Let\u0026rsquo;s show the odds at progressively more extreme values of rainfall ( \\(1\\sigma, 2\\sigma, 3\\sigma\\)  ):\nplot(x1_pred_raw, p, ylim = c(0, 1), type = \u0026#39;l\u0026#39;, col = \u0026#39;red\u0026#39;) abline(v = x1_mean, lty = 2, col = \u0026#39;gray\u0026#39;) abline(h = p_x1_mean, lty = 2, col = \u0026#39;gray\u0026#39;) # at 1 sd lines(x = rep(x1_mean + x1_sd, 2), y = c(0, boot::inv.logit(b0 + b1 * 1)),  lty = 2, col = \u0026#39;orange\u0026#39;) points(x = x1_mean + x1_sd, y = boot::inv.logit(b0 + b1 * 1)) # at 2 sd lines(x = rep(x1_mean + 2*x1_sd, 2), y = c(0, boot::inv.logit(b0 + b1 * 2)),  lty = 2, col = \u0026#39;green\u0026#39;) points(x = x1_mean + 2*x1_sd, y = boot::inv.logit(b0 + b1 * 2)) # at 3 sd lines(x = rep(x1_mean + 3*x1_sd, 2), y = c(0, boot::inv.logit(b0 + b1 * 3)),  lty = 2, col = \u0026#39;blue\u0026#39;) points(x = x1_mean + 3*x1_sd, y = boot::inv.logit(b0 + b1 * 3)) When rainfall is near it\u0026rsquo;s observed maximum value (at 3 standard deviations higher than the mean), you are now exp(b1)^3 or ~2.2X more likely to see plants than not.\n Effect size inference using another scale #  Let\u0026rsquo;s say the manager isn\u0026rsquo;t thrilled about using standard deviations in rainfall as the unit of measure. Instead, they\u0026rsquo;re focused on inches of precipitation. How do we cast these effect size calculations in terms of inches and not standard deviations? First we need to recover the unstandardized slope term, which we\u0026rsquo;ll notate as  \\(\\beta_1^{\\prime}\\)  using  \\(\\beta_1^{\\prime}=\\frac{\\beta_{1}}{\\text{sd}(\\mathbf{x}_{1})}\\)  .\nb1_unscaled \u0026lt;- b1 / x1_sd exp(b1_unscaled) # per cm exp(b1_unscaled * 2.54) # per inch exp(b1_unscaled) is the multiplicative change in odds per cm spring rainfall. It\u0026rsquo;s much smaller than exp(b1) because x1_sd is ~15cm of precip!). We now want inches. So it\u0026rsquo;s b1_unscaled * 2.54.\n  After scaling, the value of  \\(x_1\\)  in an average rainfall year is simply zero. The term involving rainfall in the model drops out because  \\(\\beta_1 \\times 0 = 0\\)  and  \\(\\text{logit}^{-1}(0.12 \u0026#43; 0)\\)  simplifies to  \\(\\text{logit}^{-1}(0.12)\\)  .\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n The odds here make at least some intuitive sense. At p = 0.53 you\u0026rsquo;re just slightly more likely than not to encounter plants at a given point at this site.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Why is this the case? Inverse logit models have the form  \\[\\begin{align*} p_{i} \u0026amp;= \\frac{e^{\\beta_{0}\u0026#43;\\beta_1x_{1i}}}{1\u0026#43;e^{\\beta_{0}\u0026#43;\\beta_1x_{1i}}} \\\\ \u0026amp;= \\text{logit}^{-1}(\\beta_0 \u0026#43; \\beta_1 x_{1i}) \\end{align*}\\]  Rearranging the equation above, we obtain  \\[\\text{logit}(p_{i})=\\text{log}\\left(\\frac{p_{i}}{1-p_{i}}\\right)=\\beta_{0}\u0026#43;\\beta_1x_{1i}\\]   \\(\\beta_1\\)  can be understood somewhat more intuitively by exponentiating both sides of the equation above  \\[\\begin{align*} \\frac{p_{i}}{1-p_{i}} \u0026amp;= e^{\\beta_{0}\u0026#43;\\beta_1x_{1i}}\\\\ \u0026amp;= e^{\\beta_{0}} \\times e^{\\beta_1x_{1i}} \\end{align*}\\]  \u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":40,"href":"/models-for-missing-data/docs/1-guide/b-config-files/iv-analysis-extras/nc-param/","title":"Non-centered parameterization","section":"Analysis / extras","content":"Non-centered parameterization #  Syntax #  parameterization info: non-centered Usage #  When you see this sort of funnel-like shape in your funnel plots,  or the compressions / \u0026ldquo;squeeze\u0026rdquo; seen in these funnel traces,  then it may be time to consider a non-centered parameterization, which you can invoke by including the YAML block above in your analysis config file.\nIn the lower panel of the funnel traces, you can see that   \\(\\sigma_{\\beta_0}\\)  drifts into smaller values and gets a bit \u0026ldquo;stuck\u0026rdquo;. Basically, the sampler can\u0026rsquo;t efficiently explore that parameter space. While stuck, the slopes  \\(\\beta_j\\)  compress / squish together, thereby creating the problematic funnel we saw in the first figure.\nIt\u0026rsquo;s possible to escape this funnel with a small reparameterization, called the \u0026ldquo;non-centered\u0026rdquo; parameterization. We won\u0026rsquo;t go into detail here, but the basic problem, and solution, is described by others. The outputs used to find evidence of a funnel (and hence a clue that the non-centered parameterization may be needed), are found here.\nResources #  Approachable, less-technical material #   Statistical rethinking (Citation: McElreath,\u0026#32;2020McElreath,\u0026#32; R.\u0026#32; (2020). \u0026#32;Statistical rethinking: A bayesian course with examples in r and stan. \u0026#32; Chapman; Hall/CRC. )  \u0026ldquo;Why hierarchical models are awesome, tricky, and Bayesian\u0026rdquo; This parameterization also appears in discussions by the Stan and greta communities: here and here.  Technical / mathy material #   A General Framework for the Parametrization of Hierarchical Models by Papaspiliopoulos et al. (Citation: 2007Papaspiliopoulos,\u0026#32; O.,\u0026#32; Roberts,\u0026#32; G.\u0026#32;\u0026amp;\u0026#32;Sköld,\u0026#32; M. \u0026#32; (2007). \u0026#32;A general framework for the parametrization of hierarchical models. Statistical Science.\u0026#32;59–73. )  Hamiltonian Monte Carlo for Hierarchical Models by Betancourt and Girolami (Citation: 2015Betancourt,\u0026#32; M.\u0026#32;\u0026amp;\u0026#32;Girolami,\u0026#32; M. \u0026#32; (2015). \u0026#32;Hamiltonian monte carlo for hierarchical models. Current trends in Bayesian methodology with applications,\u0026#32;79(30).\u0026#32;2–4. )  Appendix D in Monnahan et al. (Citation: 2017Monnahan,\u0026#32; C.,\u0026#32; Thorson,\u0026#32; J.\u0026#32;\u0026amp;\u0026#32;Branch,\u0026#32; T. \u0026#32; (2017). \u0026#32;Faster estimation of bayesian models in ecology using hamiltonian monte carlo. Methods in Ecology and Evolution,\u0026#32;8(3).\u0026#32;339–348. )   References #    Betancourt\u0026#32;\u0026amp;\u0026#32;Girolami (2015)  Betancourt,\u0026#32; M.\u0026#32;\u0026amp;\u0026#32;Girolami,\u0026#32; M. \u0026#32; (2015). \u0026#32;Hamiltonian monte carlo for hierarchical models. Current trends in Bayesian methodology with applications,\u0026#32;79(30).\u0026#32;2–4.    McElreath (2020)  McElreath,\u0026#32; R.\u0026#32; (2020). \u0026#32;Statistical rethinking: A bayesian course with examples in r and stan. \u0026#32; Chapman; Hall/CRC.    Monnahan,\u0026#32; Thorson\u0026#32;\u0026amp;\u0026#32;Branch (2017)  Monnahan,\u0026#32; C.,\u0026#32; Thorson,\u0026#32; J.\u0026#32;\u0026amp;\u0026#32;Branch,\u0026#32; T. \u0026#32; (2017). \u0026#32;Faster estimation of bayesian models in ecology using hamiltonian monte carlo. Methods in Ecology and Evolution,\u0026#32;8(3).\u0026#32;339–348.    Papaspiliopoulos,\u0026#32; Roberts\u0026#32;\u0026amp;\u0026#32;Sköld (2007)  Papaspiliopoulos,\u0026#32; O.,\u0026#32; Roberts,\u0026#32; G.\u0026#32;\u0026amp;\u0026#32;Sköld,\u0026#32; M. \u0026#32; (2007). \u0026#32;A general framework for the parametrization of hierarchical models. Statistical Science.\u0026#32;59–73.     "},{"id":41,"href":"/models-for-missing-data/posts/stratum-varying-fixed-effects/","title":"Stratum-varying fixed effects","section":"Posts","content":"Assume we have three strata,   \\(s_0\\)  ,  \\(s_1\\)  , and  \\(s_2\\)  , where  \\(s_0\\)  is the \u0026ldquo;reference\u0026rdquo; stratum – in other words,  \\(s_0\\)  is the stratum for which the 0/1 indicator is 0 across the board in the indicator matrix below (the first row):\n \\[\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\\\ 1 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\\]  B_0 + (B_1 + B_1_s1_offset * s1 + B_1_s2_offset * s2) * x_1  # in stratum s0 B_0 + (B_1) * x_1  # in stratum s1 B_0 + (B_1 + B_1_s1_offset * s1) * x_1  # in stratum s2 B_0 + (B_1 + B_1_s2_offset * s2) * x_1  # lm(y~x1*x2) model.matrix(~x1*x2, tibble(x1 = runif(5), x2 = runif(5))) "},{"id":42,"href":"/models-for-missing-data/posts/offsets/","title":"The offset term","section":"Posts","content":"Counts of things naturally scale with the length or duration of observation, the area sampled, and sampling intensity (Citation: McElreath,\u0026#32;2018McElreath,\u0026#32; R.\u0026#32; (2018). \u0026#32;Statistical rethinking: A bayesian course with examples in r and stan. \u0026#32; Chapman; Hall/CRC. ) . For instance, the longer the river stretch we survey, the more fish we\u0026rsquo;ll tend to find.\nOffset terms are used to model rates \u0026ndash; e.g., counts per unit area or time. In the context of the model, the offset term transforms the response variable from a rate to a count.\nWhy do we need an offset? #  Why can\u0026rsquo;t we simply derive a new response variable by normalizing the original counts by the relevant sampling unit? The distributions we use to model counts have support for discrete-valued variables. Transformations of the counts can violate that requirement. For instance, say we counts signs of human disturbance in 20m-by-50m plots. If we see 60 signs, that\u0026rsquo;s 60 / (20 * 50) = 0.06. Although the mean of a Poisson distributed variable can be continuous, observations cannot be. Thus, transforming the response variable from counts to a rate is incorrect.\nThe offset needs to be on the same scale as the linear predictor. In the case of a log link model, this requires the offset variable to be logged before inclusion in the model  poi_r \u0026lt;- glm(numclaims ~ x1+x2+x3,data=train, family = \u0026ldquo;poisson\u0026rdquo;, offset=log(exposure))\nTypically, we use offsets when the sampling unit (time, area, exposure) varies across observations. For example, species richness in riparian areas in arid ecosystems is often evaluated for the entire riparian area, which tend to be quite small. But the actual extent of each riparian area might differ.\n References #    McElreath (2018)  McElreath,\u0026#32; R.\u0026#32; (2018). \u0026#32;Statistical rethinking: A bayesian course with examples in r and stan. \u0026#32; Chapman; Hall/CRC.     "}]